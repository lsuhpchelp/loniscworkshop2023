{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsuhpchelp/loniscworkshop2023/blob/main/day3-4/2023_keras_mnist_v4_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHMY-zMpnVHZ"
      },
      "source": [
        "# MNIST handwritten digits classification with CNNs\n",
        "\n",
        "Ref: https://github.com/CSCfi/machine-learning-scripts\n",
        "\n",
        "In this notebook, we'll train a convolutional neural network (CNN, ConvNet) to classify MNIST digits using Keras (with Tensorflow as the compute backend).  Keras version $\\ge$ 2 is required. \n",
        "\n",
        "Note that we want you to ignore the initialization part which could be environment/platform dependent, however, focus more on the part that is related to the structure of the neural network (NN) to understand how the convolutional layers and the full connected layers are implemented in Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWCaCWGtnVHe"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D \n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "from distutils.version import LooseVersion as LV\n",
        "from keras import __version__\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
        "assert(LV(__version__) >= LV(\"2.0.0\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x31MwNUnVHn"
      },
      "source": [
        "Let's load the MNIST or Fashion-MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf6kfGotnVHp"
      },
      "source": [
        "from keras.datasets import mnist, fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "nb_classes = 10\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# one-hot encoding:\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "print()\n",
        "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
        "print('X_train:', X_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('Y_train:', Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHgnjkkinVHu"
      },
      "source": [
        "We'll have to do a bit of tensor manipulations, depending on the used backend (Theano or Tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrC7wYDynVHw"
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "if(K.image_data_format() == 'th'):\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "print('X_train:', X_train.shape)\n",
        "print('X_test:', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMudB0jinVH1"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Now we are ready to create a convolutional model.\n",
        "\n",
        " * The `Convolution2D` layers operate on 2D matrices so we input the digit images directly to the model.  \n",
        " * The `MaxPooling2D` layer reduces the spatial dimensions, that is, makes the image smaller.\n",
        " * The `Flatten` layer flattens the 2D matrices into vectors, so we can then switch to  `Dense` layers as in the MLP model. \n",
        "\n",
        "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BaZ2YPUnVH3"
      },
      "source": [
        "# number of convolutional filters to use\n",
        "nb_filters = 32\n",
        "# convolution kernel size\n",
        "kernel_size = (3, 3)\n",
        "# size of pooling area for max pooling\n",
        "pool_size = (2, 2)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(nb_filters, kernel_size,\n",
        "                 padding='valid',\n",
        "                 input_shape=input_shape,\n",
        "                 activation='relu'))\n",
        "model.add(Conv2D(nb_filters, kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=nb_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp9gIFHrnVH8"
      },
      "source": [
        "#SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDFCCNXcnVIB"
      },
      "source": [
        "## Learning\n",
        "\n",
        "Now let's train the CNN model. This is a relatively complex model, so training can be considerably slower than the previous versions, make sure you are using the GPU runtime. If you find the training time for each epoch is greater than 100s, you are probably using the CPU only runtime, change it by \"Runtime -> Change runtime type\", and then \"Reset all runtimes\", an epoch can finish in 3-4s using GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLO8wM2mnVIE"
      },
      "source": [
        "%%time\n",
        "\n",
        "# one epoch takes about 3 seconds using GPU, can be more than 100s on CPU only\n",
        "epochs = 50 \n",
        "\n",
        "history = model.fit(X_train, \n",
        "                    Y_train, \n",
        "                    epochs=epochs, \n",
        "                    batch_size=128,\n",
        "                    verbose=2,\n",
        "                    validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxQn01QFnVIJ"
      },
      "source": [
        "# plot the training and validation loss\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(history.epoch,history.history['loss'],label='training loss',color='blue')\n",
        "plt.plot(history.epoch,history.history['val_loss'],label='test loss',color='red')\n",
        "plt.legend()\n",
        "plt.title('loss')\n",
        "\n",
        "# plot the training and validation accuracy\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(history.epoch,history.history['accuracy'],label='training acc',color='blue')\n",
        "plt.plot(history.epoch,history.history['val_accuracy'],label='test acc',color='red')\n",
        "plt.legend()\n",
        "plt.title('accuracy');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZAUW9TQnVIO"
      },
      "source": [
        "## Inference\n",
        "\n",
        "With enough training epochs, the test accuracy should exceed 99%.  \n",
        "\n",
        "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html).  Even more results can be found [here](http://yann.lecun.com/exdb/mnist/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD3lFIuhnVIP"
      },
      "source": [
        "%%time\n",
        "scores = model.evaluate(X_test, Y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlwfnRunVIb"
      },
      "source": [
        "We can again take a closer look on the results. Let's begin by defining\n",
        "a helper function to show the failure cases of our classifier. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF_ZJ1AmnVIh"
      },
      "source": [
        "def show_failures(predictions, trueclass=None, predictedclass=None, maxtoshow=10):\n",
        "    rounded = np.argmax(predictions, axis=1)\n",
        "    errors = rounded!=y_test\n",
        "    print('Showing max', maxtoshow, 'first failures. '\n",
        "          'The predicted class is shown first and the correct class in parenthesis.')\n",
        "    ii = 0\n",
        "    plt.figure(figsize=(maxtoshow, 1))\n",
        "    for i in range(X_test.shape[0]):\n",
        "        if ii>=maxtoshow:\n",
        "            break\n",
        "        if errors[i]:\n",
        "            if trueclass is not None and y_test[i] != trueclass:\n",
        "                continue\n",
        "            if predictedclass is not None and predictions[i] != predictedclass:\n",
        "                continue\n",
        "            plt.subplot(1, maxtoshow, ii+1)\n",
        "            plt.axis('off')\n",
        "            if K.image_data_format() == 'th':\n",
        "                plt.imshow(X_test[i,0,:,:], cmap=\"gray\")\n",
        "            else:\n",
        "                plt.imshow(X_test[i,:,:,0], cmap=\"gray\")\n",
        "            plt.title(\"%d (%d)\" % (rounded[i], y_test[i]))\n",
        "            ii = ii + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzI18wcHnVIo"
      },
      "source": [
        "Here are the first 10 test digits the CNN classified to a wrong class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WtIPJjvQnVIp"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "show_failures(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtJrYZuhnVIt"
      },
      "source": [
        "We can use `show_failures()` to inspect failures in more detail. For example, here are failures in which the true class was \"6\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT1XJWPqnVIv"
      },
      "source": [
        "show_failures(predictions, trueclass=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMGJcmknN8Zx"
      },
      "source": [
        "#Exercise\n",
        "\n",
        "Try to build a LeNet to classify MNIST using the current notebook as a starting point, you can refer to below link as a reference:\n",
        "\n",
        "https://medium.com/@mgazar/lenet-5-in-9-lines-of-code-using-keras-ac99294c8086"
      ]
    }
  ]
}